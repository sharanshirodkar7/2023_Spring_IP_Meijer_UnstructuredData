{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "AXeLjrlw5MvI",
    "outputId": "0718166f-7504-4dc6-8351-566ee115771c"
   },
   "outputs": [],
   "source": [
    "# !pip install pytesseract\n",
    "# !pip install --upgrade azure-cognitiveservices-vision-computervision\n",
    "#!pip install opencv-python\n",
    "#!pip install azure.cognitiveservices.vision.computervision\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\akkyd\\\\Downloads'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZFPS_FJ7K4r"
   },
   "source": [
    "# Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "roTbIipE3uKD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suneetabraham/opt/anaconda3/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import urllib\n",
    "import PIL\n",
    "import numpy as np \n",
    "import urllib.request\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import random\n",
    "import io\n",
    "import re \n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import azure\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import os\n",
    "import concurrent.futures\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import language_tool_python\n",
    "from fuzzywuzzy import fuzz\n",
    "import textstat\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from string import printable\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from textstat import flesch_kincaid_grade\n",
    "from fuzzywuzzy import fuzz\n",
    "from language_tool_python import LanguageTool\n",
    "\n",
    "# initialize language tool\n",
    "tool = LanguageTool('en-US')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFSaU_npll7p"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing the non_static_images from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     340366\n",
       "False    160838\n",
       "Name: url_check, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Creating function to check if photo is static or non static\n",
    "def static_image_check(link):\n",
    "    if re.search('http://static.meijer',link):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88g9Z_hCBvHR"
   },
   "source": [
    "# Code for running Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9ItsS8auAsk6"
   },
   "outputs": [],
   "source": [
    "### Entering the code\n",
    "os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY']='fbb01c5a90c64cd6a0f468f04daae7c4'\n",
    "os.environ['COMPUTER_VISION_ENDPOINT']='https://ipmeijer.cognitiveservices.azure.com/'\n",
    "# Add your Computer Vision subscription key to your environment variables.\n",
    "if 'COMPUTER_VISION_SUBSCRIPTION_KEY' in os.environ:\n",
    "    subscription_key = os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY']\n",
    "else:\n",
    "    print(\"\\nSet the COMPUTER_VISION_SUBSCRIPTION_KEY environment variable.\\n**Restart your shell or IDE for changes to take effect.**\")\n",
    "    sys.exit()\n",
    "# Add your Computer Vision endpoint to your environment variables.\n",
    "if 'COMPUTER_VISION_ENDPOINT' in os.environ:\n",
    "    endpoint = os.environ['COMPUTER_VISION_ENDPOINT']\n",
    "else:\n",
    "    print(\"\\nSet the COMPUTER_VISION_ENDPOINT environment variable.\\n**Restart your shell or IDE for changes to take effect.**\")\n",
    "    sys.exit()\n",
    "\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyXIAQl071yf"
   },
   "source": [
    "# Defining OCR function to extract text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "subscription_key = \"5f03bfef48654bb489fe5aff1dfc37e3\"\n",
    "endpoint = \"https://ipprojectmeijer1.cognitiveservices.azure.com/\"\n",
    "\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "def capture_text(link):\n",
    "    try:\n",
    "        # Get an image with text\n",
    "        read_image_url = link\n",
    "        # Call API with URL and raw response (allows you to get the operation location)\n",
    "        read_response = computervision_client.read(read_image_url, raw=True)\n",
    "\n",
    "        # Get the operation location (URL with an ID at the end) from the response\n",
    "        read_operation_location = read_response.headers[\"Operation-Location\"]\n",
    "        # Grab the ID from the URL\n",
    "        operation_id = read_operation_location.split(\"/\")[-1]\n",
    "\n",
    "        # Call the \"GET\" API and wait for it to retrieve the results \n",
    "        while True:\n",
    "            read_result = computervision_client.get_read_result(operation_id)\n",
    "            if read_result.status not in ['notStarted', 'running']:\n",
    "                break\n",
    "    \n",
    "        # Print the detected text, line by line\n",
    "        x=''\n",
    "        if read_result.status == OperationStatusCodes.succeeded:\n",
    "            for text_result in read_result.analyze_result.read_results:\n",
    "                for line in text_result.lines:\n",
    "                    x+= ' '+line.text\n",
    "        return x\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\"Error: {}\".format(ex))\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Run CHAT GPT API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "#### Function to create product description for the data \n",
    "def product_description(x):\n",
    "    openai.api_key =\"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\"\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=\"Create product description in 50 words. Keep it clean and formatted\".format(x),\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    text = response['choices'][0]['text']\n",
    "    time.sleep(rand)\n",
    "    return(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Scoring Algorithm Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def length_score(text, temp_score):\n",
    "#     if (len(text)/ 300) >= 0.9 :\n",
    "#         final_score= temp_score*1\n",
    "#     else:\n",
    "#     return final_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def text_analysis(df, text_column_name):\n",
    "#     # initialize lists to store scores for each row\n",
    "#     readability_scores = []\n",
    "#     grammar_scores = []\n",
    "#     relevance_scores = []\n",
    "#     sentiment_scores = []\n",
    "\n",
    "#     # iterate over rows in the DataFrame\n",
    "#     for index, row in df.iterrows():\n",
    "#         # extract text and name from the row\n",
    "#         text = row[text_column_name]\n",
    "#         name = row['MarketingName']\n",
    "        \n",
    "#         # compute readability score\n",
    "#         text = re.sub(r'[^a-zA-Z0-9\\s]+', '', text).strip()\n",
    "#         text = re.sub(r'\\s+', ' ', text.strip())\n",
    "#         readability_score_temp = flesch_kincaid_grade(text)\n",
    "#         if readability_score_temp <= 10:\n",
    "#             readability = 1 \n",
    "#         else:\n",
    "#             readability = 0 \n",
    "#         readability_scores.append(readability)\n",
    "\n",
    "#         # compute grammar score\n",
    "#         grammar_score = 1 - len(tool.check(text))/len(text.split())\n",
    "#         grammar_scores.append(grammar_score)\n",
    "\n",
    "#         # compute relevance score\n",
    "#         relevance_score = fuzz.token_set_ratio(text, name)/100\n",
    "#         relevance_scores.append(relevance_score)\n",
    "\n",
    "#         # compute sentiment score\n",
    "#         sentiment = TextBlob(text).sentiment.polarity\n",
    "#         sentiment_scores.append(sentiment)\n",
    "\n",
    "#     # add scores to DataFrame\n",
    "#     df['readability_score'] = readability_scores\n",
    "#     df['grammar_score'] = grammar_scores\n",
    "#     df['relevance_score'] = relevance_scores\n",
    "#     df['sentiment_score'] = sentiment_scores\n",
    "\n",
    "#     # assign weights for each metric and compute final score\n",
    "#     relevance_wt = 0.3\n",
    "#     grammar_wt = 0.3\n",
    "#     readability_wt = 0.3\n",
    "#     sentiment_wt = 0.10\n",
    "#     df['temp_score'] = (relevance_wt * df['relevance_score'] +\n",
    "#                         readability_wt * df['readability_score'] +\n",
    "#                         sentiment_wt * df['sentiment_score'] +\n",
    "#                         grammar_wt * df['grammar_score'])\n",
    "#     df['final_score'] = df.apply(lambda row: length_score(row[text_column_name], row['temp_score']), axis=1)\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]+', '', text).strip()\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    return text\n",
    "def length(text):\n",
    "    x=len(text.split())\n",
    "    return x\n",
    "def errors(text):\n",
    "    x=len(tool.check(text))\n",
    "    return x\n",
    "def sent(text):\n",
    "    sentiment = TextBlob(text).sentiment.polarity\n",
    "    return sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New\n"
     ]
    }
   ],
   "source": [
    "print('Completed')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
